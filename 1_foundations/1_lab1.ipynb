{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic API Key exists and begins sk-ant-a\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "# Even for other LLM providers like Gemini, you still use this OpenAI import - see Guide 9 for why\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI(base_url = \"https://api.anthropic.com/v1/\", api_key = anthropic_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"What is 2+2?\"\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a clock's hour and minute hands overlap at 12:00, at what exact time will they next overlap?\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"claude-sonnet-4-5\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a clock takes 6 seconds to strike 4 o'clock (with equally spaced chimes), how many seconds will it take to strike 8 o'clock?\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to figure out the timing pattern of the clock chimes.\n",
      "\n",
      "When a clock strikes 4 o'clock, it chimes 4 times.\n",
      "\n",
      "The key insight is that with 4 chimes, there are only 3 intervals (spaces) between them:\n",
      "- Chime 1 → gap → Chime 2 → gap → Chime 3 → gap → Chime 4\n",
      "\n",
      "If 4 chimes take 6 seconds total, and there are 3 intervals between them:\n",
      "- Time per interval = 6 seconds ÷ 3 = 2 seconds\n",
      "\n",
      "For 8 o'clock, the clock chimes 8 times, which means there are 7 intervals between the chimes:\n",
      "- Chime 1 → gap → Chime 2 → gap → Chime 3 → gap → Chime 4 → gap → Chime 5 → gap → Chime 6 → gap → Chime 7 → gap → Chime 8\n",
      "\n",
      "With 7 intervals at 2 seconds each:\n",
      "- Total time = 7 × 2 = 14 seconds\n",
      "\n",
      "Therefore, it will take **14 seconds** to strike 8 o'clock.\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I need to figure out the timing pattern of the clock chimes.\n",
       "\n",
       "When a clock strikes 4 o'clock, it chimes 4 times.\n",
       "\n",
       "The key insight is that with 4 chimes, there are only 3 intervals (spaces) between them:\n",
       "- Chime 1 → gap → Chime 2 → gap → Chime 3 → gap → Chime 4\n",
       "\n",
       "If 4 chimes take 6 seconds total, and there are 3 intervals between them:\n",
       "- Time per interval = 6 seconds ÷ 3 = 2 seconds\n",
       "\n",
       "For 8 o'clock, the clock chimes 8 times, which means there are 7 intervals between the chimes:\n",
       "- Chime 1 → gap → Chime 2 → gap → Chime 3 → gap → Chime 4 → gap → Chime 5 → gap → Chime 6 → gap → Chime 7 → gap → Chime 8\n",
       "\n",
       "With 7 intervals at 2 seconds each:\n",
       "- Total time = 7 × 2 = 14 seconds\n",
       "\n",
       "Therefore, it will take **14 seconds** to strike 8 o'clock."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Healthcare Prior Authorization\n",
       "\n",
       "## Why This Is Prime for Agentic AI\n",
       "\n",
       "**The Problem:**\n",
       "Prior authorization is one of healthcare's most painful administrative burdens. Providers spend 13+ hours per week per physician on prior auths, with 88% reporting it leads to care delays. The process involves checking insurance requirements, gathering clinical documentation, submitting forms, and following up—often repeatedly.\n",
       "\n",
       "**Why Agents Excel Here:**\n",
       "\n",
       "1. **Multi-system orchestration** - Agents can autonomously navigate insurance portals, EHR systems, and state databases that weren't designed to talk to each other\n",
       "\n",
       "2. **Complex decision trees** - Each payer has different requirements for different procedures. Agents can reason through: \"Does this patient's diagnosis code + procedure + insurance plan require prior auth? What specific documentation is needed?\"\n",
       "\n",
       "3. **Persistent follow-up** - Agents can check status every 6 hours, automatically escalate delayed requests, and handle back-and-forth clarification requests without human handoffs\n",
       "\n",
       "4. **Learning from denials** - Agents can analyze why auths get denied and automatically strengthen future submissions\n",
       "\n",
       "**Business Model:**\n",
       "- Charge per successful authorization or subscription per provider\n",
       "- ROI is crystal clear: save 10+ staff hours per auth × $30-50/hour\n",
       "- Reduces patient care delays (strong clinical outcome tie-in)\n",
       "\n",
       "**Why Now:**\n",
       "- APIs from major payers are finally emerging (thanks to CMS mandates)\n",
       "- LLMs can understand clinical context and insurance policy language\n",
       "- Desperate market—prior auth volume up 25% in 3 years\n",
       "\n",
       "This combines high pain, clear ROI, and technical moats that agents specifically provide."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Pick a business area that is worth exploring for an Agentic AI opportunity.\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model = model_name,\n",
    "    messages = messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.choices[0].message.content\n",
    "display(Markdown(business_idea))\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Healthcare Prior Authorization\n",
       "\n",
       "## Why This Is Prime for Agentic AI\n",
       "\n",
       "**The Problem:**\n",
       "Prior authorization is one of healthcare's most painful administrative burdens. Providers spend 13+ hours per week per physician on prior auths, with 88% reporting it leads to care delays. The process involves checking insurance requirements, gathering clinical documentation, submitting forms, and following up—often repeatedly.\n",
       "\n",
       "**Why Agents Excel Here:**\n",
       "\n",
       "1. **Multi-system orchestration** - Agents can autonomously navigate insurance portals, EHR systems, and state databases that weren't designed to talk to each other\n",
       "\n",
       "2. **Complex decision trees** - Each payer has different requirements for different procedures. Agents can reason through: \"Does this patient's diagnosis code + procedure + insurance plan require prior auth? What specific documentation is needed?\"\n",
       "\n",
       "3. **Persistent follow-up** - Agents can check status every 6 hours, automatically escalate delayed requests, and handle back-and-forth clarification requests without human handoffs\n",
       "\n",
       "4. **Learning from denials** - Agents can analyze why auths get denied and automatically strengthen future submissions\n",
       "\n",
       "**Business Model:**\n",
       "- Charge per successful authorization or subscription per provider\n",
       "- ROI is crystal clear: save 10+ staff hours per auth × $30-50/hour\n",
       "- Reduces patient care delays (strong clinical outcome tie-in)\n",
       "\n",
       "**Why Now:**\n",
       "- APIs from major payers are finally emerging (thanks to CMS mandates)\n",
       "- LLMs can understand clinical context and insurance policy language\n",
       "- Desperate market—prior auth volume up 25% in 3 years\n",
       "\n",
       "This combines high pain, clear ROI, and technical moats that agents specifically provide."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "    \"content\": f\"Present a pain point in {business_idea} that is ripe for Agentic AI opportunity.\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model = model_name,\n",
    "    messages = messages\n",
    ")\n",
    "\n",
    "pain_point = response.choices[0].message.content\n",
    "display(Markdown(pain_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Agentic AI Solution: AutoAuth Intelligence Platform\n",
       "\n",
       "## System Architecture\n",
       "\n",
       "### Core Agent Framework\n",
       "\n",
       "**1. Orchestrator Agent (Control Tower)**\n",
       "- Receives prior auth requests from EHR integration\n",
       "- Decomposes task into sub-goals: eligibility check → requirements gathering → documentation assembly → submission → follow-up\n",
       "- Coordinates specialist agents and maintains state across multi-day workflows\n",
       "- Handles exceptions and escalates to humans when confidence drops below threshold\n",
       "\n",
       "**2. Specialist Agent Team**\n",
       "\n",
       "**Payer Intelligence Agent**\n",
       "- Maintains dynamic knowledge base of payer-specific requirements\n",
       "- Continuously scrapes payer websites, API documentation, and policy updates\n",
       "- Learns from historical approvals/denials to identify unstated requirements\n",
       "- Maps procedure codes (CPT) + diagnosis codes (ICD-10) → specific payer rules\n",
       "\n",
       "**Clinical Documentation Agent**\n",
       "- Connects to EHR via FHIR APIs\n",
       "- Extracts relevant clinical notes, lab results, imaging reports\n",
       "- Understands medical context using healthcare-specific LLM (fine-tuned on clinical language)\n",
       "- Generates missing documentation requests with specific clinical rationale\n",
       "- Creates evidence-based narratives that map clinical facts to payer medical necessity criteria\n",
       "\n",
       "**Portal Navigation Agent**\n",
       "- Uses browser automation (Playwright/Selenium) + vision models for legacy portals without APIs\n",
       "- Learns each payer portal's unique workflow (UnitedHealthcare vs Anthem vs BCBS)\n",
       "- Handles CAPTCHAs, multi-factor auth (with provider credentials vault)\n",
       "- Fills forms with intelligent field mapping\n",
       "- Takes screenshots for audit trails\n",
       "\n",
       "**Submission & Follow-up Agent**\n",
       "- Monitors submission status across multiple channels (API, portal, fax confirmation)\n",
       "- Implements retry logic with exponential backoff\n",
       "- Checks status every 4-6 hours\n",
       "- Detects \"pending additional information\" states and routes to Clinical Documentation Agent\n",
       "- Escalates approaching deadlines (e.g., 3 days before auto-denial)\n",
       "\n",
       "**Appeals Agent**\n",
       "- Activates on denials\n",
       "- Analyzes denial reason codes and payer explanations\n",
       "- Generates peer-to-peer meeting requests with talking points\n",
       "- Drafts appeals letters citing medical literature and payer policy contradictions\n",
       "- Tracks appeal deadlines and higher-level appeal paths\n",
       "\n",
       "## Technical Implementation\n",
       "\n",
       "### Integration Layer\n",
       "```\n",
       "Provider EHR (Epic/Cerner) \n",
       "    ↓ (FHIR API)\n",
       "AutoAuth Platform\n",
       "    ↓\n",
       "├─ Payer APIs (CAQH ProView, payer-specific)\n",
       "├─ Browser automation (legacy portals)\n",
       "├─ Fax gateway (for dinosaur payers)\n",
       "└─ Eligibility verification (270/271 EDI)\n",
       "```\n",
       "\n",
       "### Agent Technology Stack\n",
       "- **LLM Backbone**: GPT-4 for reasoning + healthcare-specific model (Med-PaLM, BioGPT) for clinical understanding\n",
       "- **Agent Framework**: LangGraph for complex workflow orchestration with cycles and human-in-the-loop\n",
       "- **Memory Systems**: \n",
       "  - Vector DB (Pinecone/Weaviate) for semantic search of payer policies\n",
       "  - SQL for structured auth history and success patterns\n",
       "- **Tool Integration**: Function calling for EHR queries, form filling, API submissions\n",
       "- **Monitoring**: LangSmith for tracing multi-agent workflows and debugging failures\n",
       "\n",
       "### Key Differentiators\n",
       "\n",
       "**1. Adaptive Learning Pipeline**\n",
       "- Every denial triggers analysis: Was documentation insufficient? Wrong codes? Payer pattern change?\n",
       "- Reinforcement learning from outcomes: Successful auth patterns are upweighted\n",
       "- A/B testing narratives: Track which documentation styles improve approval rates per payer\n",
       "\n",
       "**2. Predictive Approval Scoring**\n",
       "- Before submission, agent scores likelihood of approval (based on historical data)\n",
       "- Flags high-risk cases for human review with specific concerns\n",
       "- Suggests documentation enhancements to improve approval odds\n",
       "\n",
       "**3. Human-in-the-Loop Design**\n",
       "- Dashboard shows agent's reasoning chain for each decision\n",
       "- Providers can edit generated narratives before submission\n",
       "- Configurable automation levels (full auto → review-before-submit → agent-assist)\n",
       "- One-click escalation to human auth specialists for complex cases\n",
       "\n",
       "## Business Model & GTM\n",
       "\n",
       "### Pricing\n",
       "**Tiered Model:**\n",
       "- **Per-Authorization**: $15-25 per approved auth (only charge on success)\n",
       "- **Subscription**: $2,000-5,000/month per provider for unlimited auths\n",
       "- **Enterprise**: Custom pricing for health systems (100+ providers)\n",
       "\n",
       "**ROI Calculator for Providers:**\n",
       "- Current cost: 10 hours × $40/hour = $400 per auth\n",
       "- AutoAuth cost: $20\n",
       "- Savings: $380 per auth\n",
       "- Typical provider: 20 auths/week = $7,600/week saved = $395K/year\n",
       "\n",
       "### Go-to-Market\n",
       "\n",
       "**Phase 1: Specialty Pilots (Months 1-6)**\n",
       "- Target high-volume specialties: Oncology, Orthopedics, Cardiology\n",
       "- Partner with 3-5 mid-size practices (10-30 providers)\n",
       "- Focus on 2-3 major payers (UnitedHealthcare, Aetna) to perfect workflows\n",
       "- Build case studies showing 80%+ automation rate\n",
       "\n",
       "**Phase 2: Health System Expansion (Months 6-18)**\n",
       "- Sell to health system C-suite (CFO + CMIO)\n",
       "- Integrate with Epic/Cerner at enterprise level\n",
       "- Pitch: \"Redeploy auth staff to patient care\" + \"Reduce revenue delays\"\n",
       "- Deploy across all specialties within system\n",
       "\n",
       "**Phase 3: Payer Partnerships (Months 18+)**\n",
       "- Flip the model: Sell to insurance companies\n",
       "- Pitch: \"Reduce your auth processing costs by 60%\"\n",
       "- Become the standard interface between providers and payers\n",
       "- Potential acquisition target for major payer\n",
       "\n",
       "### Competitive Moats\n",
       "\n",
       "1. **Data Flywheel**: More auths → better payer requirement models → higher approval rates → more customers\n",
       "2. **Integration Complexity**: Deep EHR + payer portal integrations take 12-18 months to replicate\n",
       "3. **Clinical AI Expertise**: Requires team with both healthcare domain knowledge and cutting-edge AI capabilities\n",
       "4. **Regulatory Compliance**: HIPAA, SOC 2, payer credentialing create barriers to entry\n",
       "\n",
       "## Risk Mitigation\n",
       "\n",
       "**Regulatory Risks:**\n",
       "- Maintain human oversight for all clinical decision points\n",
       "- Provider maintains legal responsibility (agent is \"scribe\")\n",
       "- Regular audits of agent decisions vs. human baseline\n",
       "\n",
       "**Technical Risks:**\n",
       "- Payer portals change without notice → Vision models + change detection systems\n",
       "- API downtime → Automatic fallback to portal automation or fax\n",
       "- Hallucination risk → Multiple validation checkpoints, confidence scoring\n",
       "\n",
       "**Market Risks:**\n",
       "- Large EHR vendors build competing features → Move upmarket to enterprise, emphasize multi-EHR support\n",
       "- Payers resist automation → Position as reducing their costs too, pursue payer partnerships\n",
       "\n",
       "## Success Metrics (12-month targets)\n",
       "\n",
       "- **Automation Rate**: 75% of auths require zero human intervention\n",
       "- **Approval Rate**: Match or exceed human baseline (target: 85%+)\n",
       "- **Time to Approval**: Reduce from 5-7 days to 2-3 days average\n",
       "- **Customer Metrics**: \n",
       "  - 20 health systems (2,000+ providers)\n",
       "  - 95%+ customer retention\n",
       "  - Net Promoter Score > 50\n",
       "- **Financial**: $10M ARR, path to $50M by month 24\n",
       "\n",
       "---\n",
       "\n",
       "This solution directly addresses the pain points with technology specifically suited for multi-step, cross-system workflows that agents handle better than traditional automation. The key is starting narrow (specialty + payer combos), proving ROI, then scaling the data flywheel."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "    \"content\": f\"Given the pain points listed as {pain_point} in {business_idea}, propose an agentic ai solution to solve it.\"}\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model = model_name,\n",
    "    messages = messages\n",
    ")\n",
    "\n",
    "proposed_solution = response.choices[0].message.content\n",
    "display(Markdown(proposed_solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
